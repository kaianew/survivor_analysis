{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas\n",
    "import os\n",
    "import glob\n",
    "import statistics as stats\n",
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_nodes  average_degree  average_clustering  percent_largest_component  \\\n",
      "0         20       22.800000            0.188801                  90.000000   \n",
      "1         20       31.600000            0.136265                 100.000000   \n",
      "2         16       25.000000            0.196874                  87.500000   \n",
      "3         16       21.000000            0.256924                  93.750000   \n",
      "4         20       20.500000            0.152052                  95.000000   \n",
      "5         20       20.000000            0.143703                  95.000000   \n",
      "6         17       14.588235            0.213853                  88.235294   \n",
      "7         16       14.875000            0.193372                 100.000000   \n",
      "8         16       18.750000            0.186348                  93.750000   \n",
      "9         18       16.222222            0.181123                  88.888889   \n",
      "10        16       23.750000            0.255011                 100.000000   \n",
      "11        16       18.250000            0.194819                  93.750000   \n",
      "12        16       12.875000            0.289602                  93.750000   \n",
      "13        18       19.666667            0.141825                  94.444444   \n",
      "14        16       14.375000            0.384891                  75.000000   \n",
      "15        16       18.125000            0.181034                  87.500000   \n",
      "16        16       15.500000            0.193554                  87.500000   \n",
      "17        18       24.000000            0.159931                  88.888889   \n",
      "18        18       16.444444            0.262599                  94.444444   \n",
      "19        18       20.333333            0.215450                 100.000000   \n",
      "\n",
      "    average_weight average_strong_ties  \n",
      "0         2.746988                   3  \n",
      "1         3.361702                 2.7  \n",
      "2         3.921569                2.75  \n",
      "3         3.000000               2.125  \n",
      "4         2.628205                 2.6  \n",
      "5         2.272727                 2.4  \n",
      "6         2.530612            2.235294  \n",
      "7         2.767442               1.625  \n",
      "8         2.678571               3.125  \n",
      "9         2.433333            2.666667  \n",
      "10        3.275862                   2  \n",
      "11        2.807692               3.375  \n",
      "12        2.710526                 2.5  \n",
      "13        2.391892            2.333333  \n",
      "14        3.484848                   2  \n",
      "15        2.589286                 2.5  \n",
      "16        2.254545               2.125  \n",
      "17        2.842105            3.444444  \n",
      "18        2.426230            2.777778  \n",
      "19        2.951613            3.222222  \n",
      "Average number of nodes over S1-20: 17.35\n",
      "Average average degree: 19.432745098039216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/mbgtwhns405crk_pd0vnvd3c0000gn/T/ipykernel_9864/3704169423.py:52: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  basic_metrics_df = pandas.concat([basic_metrics_df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "file_pattern = \"*graph.graphml\"\n",
    "graph_files = glob.glob(file_pattern)\n",
    "\n",
    "graphs = []\n",
    "for file in graph_files:\n",
    "    graph = nx.read_graphml(file)\n",
    "    graphs.append(graph)\n",
    "\n",
    "# Create dataframe that looks like this:\n",
    "# Num nodes | average (weighted) degree | average (weighted) clustering | size of largest component (as a percentage) \n",
    "# | average weight | average num partners over the average weight\n",
    "\n",
    "# Make empty dataframe\n",
    "columns = ['num_nodes', 'average_degree', 'average_clustering', 'percent_largest_component', 'average_weight', 'average_strong_ties']\n",
    "basic_metrics_df = pandas.DataFrame(columns=columns)\n",
    "\n",
    "for graph in graphs:\n",
    "    num_nodes = len(graph.nodes)\n",
    "\n",
    "    degrees = dict(graph.degree(weight='weight'))\n",
    "    degree_list = list(degrees.values())\n",
    "    average_degree = stats.mean(degree_list)\n",
    "\n",
    "    clustering_weighted = nx.clustering(graph, weight=\"weight\")\n",
    "    clustering_weighted = list(clustering_weighted.values())\n",
    "    average_clustering = stats.mean(clustering_weighted)\n",
    "\n",
    "    components = nx.connected_components(graph)\n",
    "    largest_component = max(components, key=len)\n",
    "    largest_component_size = len(largest_component)\n",
    "    largest_component_percentage = largest_component_size / num_nodes * 100\n",
    "\n",
    "    edge_weights_dict = nx.get_edge_attributes(graph, 'weight')\n",
    "    edge_weights_list = list(edge_weights_dict.values())\n",
    "    average_weight = stats.mean(edge_weights_list)\n",
    "\n",
    "    strongly_tied_friends = []\n",
    "    # Go through nodes in the graph, check if weight > average, if so, add to ctr\n",
    "    for node in graph.nodes:\n",
    "        ctr = 0\n",
    "        for neighbor in graph.neighbors(node):\n",
    "            weight = graph[node][neighbor]['weight']\n",
    "            if weight > average_weight:\n",
    "                ctr += 1\n",
    "        strongly_tied_friends.append(ctr)\n",
    "    \n",
    "    average_strong_friends = stats.mean(strongly_tied_friends)\n",
    "\n",
    "    new_row = pandas.DataFrame({'num_nodes': [num_nodes], 'average_degree': [average_degree], \n",
    "    'average_clustering': [average_clustering], 'percent_largest_component': [largest_component_percentage], 'average_weight': [average_weight], \n",
    "    'average_strong_ties': [average_strong_friends]})\n",
    "    basic_metrics_df = pandas.concat([basic_metrics_df, new_row], ignore_index=True)\n",
    "\n",
    "print(basic_metrics_df)\n",
    "\n",
    "# Print to LaTeX for the writeup\n",
    "latex_code = basic_metrics_df.to_latex(index=False)\n",
    "with open(\"network_table.tex\", \"w\") as f:\n",
    "    f.write(latex_code)\n",
    "\n",
    "# Find averages of all the averages for the slides + writeup\n",
    "avg_nodes = stats.mean(basic_metrics_df['num_nodes'])\n",
    "print(f'Average number of nodes over S1-20: {avg_nodes}')\n",
    "\n",
    "avg_avg_degree = stats.mean(basic_metrics_df['average_degree'])\n",
    "print(f'Average average degree: {avg_avg_degree}')\n",
    "\n",
    "# Measures how tightly connected nodes' neighbors are to one another, but weighted\n",
    "# Lower clustering coefficient -- neighbors are not strongly connected\n",
    "avg_avg_clustering = stats.mean(basic_metrics_df['average_clustering'])\n",
    "print(f'Average average clustering coefficient: {avg_avg_clustering}')\n",
    "\n",
    "avg_percent_component = stats.mean(basic_metrics_df['percent_largest_component'])\n",
    "print(f'Average percentage size of largest component: {avg_percent_component}')\n",
    "\n",
    "avg_avg_weight = stats.mean(basic_metrics_df['average_weight'])\n",
    "print(f'Average average weight: {avg_avg_weight}')\n",
    "\n",
    "avg_avg_strong_ties = stats.mean(basic_metrics_df['average_strong_ties'])\n",
    "print(f'Average average strong ties: {avg_avg_strong_ties}')\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
